---
title: "HW 2"
author: "Claire Chen"
date: today
format: pdf
editor: visual
---

```{r message=FALSE, warning=FALSE}
library(readr)
library(dplyr)
library(tidyr)
library(knitr)
library(scales)
library(haven)
library(labelled)
library(report)
library(broom)
library(ggplot2)
library(patchwork)
```

# Question 1

Import the file. Recode the variables “sex”, “race”, and “happy” to factors. Use the glimpse() function and provide the output.

```{r}
df <- read_sav(
  "https://github.com/felixthoemmes/hwdatasets/blob/master/sshw2_clean.sav?raw=true")

df <- df |>
  mutate(
    sex = to_factor(sex), 
    race = to_factor(race), 
    happy = to_factor(happy))

glimpse(df)
```

# Question 2

Generate a table (using the kable function) that shows the percentages of males and females in the total sample. Please use the summarize() function in dplyr.

```{r}
df |>
  summarize(
    Male = percent(sum(sex == "Male") / n(), accuracy = 0.01),
    Female = percent(sum(sex == "Female") / n(), accuracy = 0.01)) |>
  kable(caption = "Percentages of Males and Females in the Total Sample")
```

# Question 3

Generate a well-formatted (cross)-table that shows the percentages of males and females, within the three categories of “race”. Specifically, the table should show the percentage of male and female within each race.

```{r}
race_by_sex <- df |>
  group_by(race) |>
  summarize(
    Male = percent(sum(sex == "Male") / n(), accuracy = 0.01),
    Female = percent(sum(sex == "Female") / n(), accuracy = 0.01))

race_by_sex |> 
  kable(caption = "Precentages of Males and Females by Race")
```

# Question 4

Using ggplot, first generate a barplot of the percentages of the cross-table that you generated in the previous question. Then, using the exact same data, generate a dot plot that shows the same percentages. In a last step, ensure that the two graphs are shown side-by-side in your document.

```{r}
race_by_sex <- df |>
  group_by(race) |>
  summarize(
    Male = sum((sex == "Male") / n() *100),
    Female = sum(sum(sex == "Female") / n() * 100)) |>
  pivot_longer(cols = c(Male, Female),
               names_to = "Sex",
               values_to = "Percentage")

barplot_race_by_sex <- ggplot(race_by_sex, 
                              aes(x = race, y = Percentage, fill = Sex)) +
  geom_bar(stat = "identity") +
  labs(x = "Race", 
       y = "Percentage (%)") +
  theme(legend.position = "bottom")

dotplot_race_by_sex <- ggplot(race_by_sex, 
                              aes(x = race, y = Percentage, color = Sex)) +
  geom_point(size = 2, 
             position = position_dodge(width = 0.15)) +
  labs(x = "Race", 
       y = "Percentage (%)") +
  scale_y_continuous(limits = c(0, 100)) +
  theme(legend.position = "bottom")

combined_plot <- barplot_race_by_sex + dotplot_race_by_sex +
  plot_annotation(
    title = "Barplot and Dotplot of Percentages of Males and Females by Race")

combined_plot
```

# Question 5

Using dplyr, compute and report the percentage of respondents that have a value of “Very Happy” on the variable called “happy”. Then report the percentage of males and females within the “Very Happy” category. Display all this information in a single table.

```{r}
happy_group <- df |>
  summarize(Overall = percent(sum(happy == "Very Happy", na.rm = TRUE) / n(),
                              accuracy = 0.01))

happy_by_sex <- df |>
  filter(happy == "Very Happy") |>
  summarize(Males = percent(sum(sex == "Male") / n(), accuracy = 0.01),
            Females = percent(sum(sex == "Female") / n(), accuracy = 0.01))

combined_happy <- bind_cols(happy_group, happy_by_sex)

combined_happy |>
  kable(caption = "Percentages of 'Very Happy' in Overall Sample & by Sex")
```

# Question 6

Using ggplot, construct a kernel density estimate of the variable “age”, but separately for males and females. Make sure to overlay the two kernel density estimates in a single plot, and visually separate them by using different colors for males and females. Then add two vertical lines for the mean age for males, and the mean age for females. Add meaningful labels to all axes and add a caption to the plot.

```{r}
mean_ages <- df |>
  group_by(sex) |>
  summarize(mean_age = mean(age))

ggplot(df, aes(x = age, fill = sex, color = sex)) +
  geom_density(alpha = 0.3) +
  geom_vline(data = mean_ages, 
             aes(xintercept = mean_age, color = sex), 
             linewidth = 0.5) +
  labs(title = "Kernel Density Estimate of Age by Sex with Mean Age Lines",
       x = "Age",
       y = "Density") +
  theme(legend.position = "bottom") +
  theme(plot.title = element_text(size = 12))
```

# Question 7

Construct a new variable “agebin” that creates three distinct age categories, defined as: young: age \<= 20, middle-aged: 21 \<= age \<= 50, older: age \>= 51. Then construct a barplot of the frequencies of these three categories.

```{r}
df <- df |>
  mutate(
    agebin = case_when(
      age <= 20 ~ "young",
      age >= 21 & age <= 50 ~ "middle-aged",
      age >= 51 ~ "old"))

ggplot(df, aes(x = agebin)) +
  geom_bar() +
  scale_x_discrete(limits = c("young", "middle-aged", "old")) +
  labs(title = "Frequencies of Age Bins", x = "Age Bins", y = "Frequency")
```

# Question 8

Frequentist statistics views probability as the long run frequency of events. They are concerned with the overall rate of false positives in a statistical method. Frequentist statistics assumes that the population parameter is a fixed but unknown quantity. They rely on the idea of "sampling distribution," which is a distribution of results from hypothetical repetition of sampling assuming a true null hypothesis. Based on sampling distribution, Frequentists use hypothesis testing and p-values to decide whether they would accept or reject the null hypothesis.

Bayesian statistics views probability as a measure to quantify our belief or uncertainty about an event. They are concerned with the rate of errors among the positives in a statistical method. Bayesian statistics assumes that the population parameter is a random and unknown quantity. Before they collect data, Bayesian statisticians use a probability distribution to describe the uncertainty about the unknown population parameter. Then data is collected and the resulting likelihood function is used to update their belief about the unknown population parameter, using the Bayes' theorem. Inference is made based on the latter probability distribution.

# Question 9

The L~2~ norm corresponds to the mean of a data set, and it minimizes the sum of squared differences between each data point and the central value, or mean in this case. Any data points that are far from the central value, also known as outliers, are placed with heavier weight as squaring the difference would result in a much larger value than squaring a small difference. Therefore, the L~3~ norm would minimize the sum of cubed (absolute) differences between each data point and the central value. Compared to the L~2~ norm, the L~3~ norm would be even more sensitive to outliers as the cubed differences would be heavily affected by large deviations. The effect of the cubic function results in a steeper increase as the magnitude of deviation grows than that of a squared function. Therefore, the central value of the the L~3~ norm would be much affected by outliers and shift toward them.

# Question 10

Understanding the context and domain is important when interpreting measures of central tendency and dispersion of data sets as different contexts will call for different focuses on which measure of central tendency and dispersion to use. The three measures of central tendency—mean, median, and mode—provide different insights about the central value of a data set, while dispersion measurements like the range, variance, and standard deviation tell us about the spread and variability of a data set. Depending on the field in which a data set is from, one measure of central tendency and dispersion may be more informative than the other measures, and professionals in the specific field will focus on the more informative measurements.

For instance, in financial data like income statistics, the median and the mode tend to be more informative than the mean as the mean is sensitive to outliers. Median and the mode are more reflective of what an "average" (not in the same sense of the mathematical "mean") person is making as their yearly salary, whereas the mean can appear as much higher or lower. Additionally, income statistics may be concerned with the dispersion of its data set using range to understand how wide is the wealth disparity. On the other hand, in medical data like the effectiveness of a drug, the mean and standard deviation tend to be chosen as the measure of central tendency and dispersion, especially in cases where an experiment is being conducted. Medical data is concerned with whether a treatment is effective and can be further used in clinical settings, so having the mean and standard deviation allows for hypothesis testing and deciding the incompatibility between the experiment results and the null hypothesis.

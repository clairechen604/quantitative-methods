---
title: "HW7"
author: "Claire Chen"
date: today
format: pdf
editor: visual
---

```{r, message=FALSE, warning=FALSE}
library(haven)
library(emmeans)
library(readr)
library(labelled)
library(rstanarm)
library(BayesFactor)
library(easystats)
library(tidyverse)
library(BFpack)
library(knitr)
library(scales)
library(ggdist)
library(pwr)

df <- read_sav(
  "https://github.com/felixthoemmes/hwdatasets/blob/master/purduereading.sav?raw=true")
```

# Question 1

First, import the data, and recode the grouping variable as a factor. In order to retain labels on the levels. I recommend the use of the to_factor() function in the labelled package. Then generate a well-formatted table that reports the count and the percentage of children in all three groups. In a second step, generate a second table that contains the overall mean and the overall standard deviation of reading scores in the sample, and mean and standard deviation of reading scores in the three treatment groups. Present all means and standard deviations in a single table.

```{r}
df <- df |>
  mutate(group = to_factor(group))

df |>
  group_by(group) |>
  summarize(count = n(),
            percentage = percent(count / nrow(df), accuracy = 0.01)) |>
  kable(caption = "Count and Percentage of Children in Groups")

summary_overall <- df |>
  summarize(mean = mean(posttest),
            sd = sd(posttest)) |>
  mutate(group = "Overall") |>
  select(3, 1, 2)

summary_group <- df |>
  group_by(group) |>
  summarize(mean = mean(posttest),
            sd = sd(posttest))

bind_rows(summary_overall, summary_group) |>
  kable(digits = 2,
        caption = "Mean and Standard Deviation of Reading Scores")
```

# Question 2

In addition to the descriptive statistics above, also generate a graphical display. Generate a so-called rain-cloud plot, which is a combination of a kernel density estimate, and a dot plot. I strongly recommend the use of the ggdist package to achieve this. Comment briefly on differences in central tendency, and variability between the three groups. Expected length is about 1-3 sentences.

```{r}
ggplot(df, aes(x = group, y = posttest, fill = group)) +
  stat_halfeye(adjust = 2, width = 0.6, 
               justification = -0.4, .width = 0, point_color = NA) +
  geom_point(size = 0.5, alpha = 0.6, 
             position = position_jitter(seed = 1, width = 0.1)) +
  coord_flip() +
  labs(title = "Rain-Cloud Plot of Reading Scores by Group", 
       x = "Group", y = "Reading Scores") +
  theme(legend.position = "bottom")
```

DRTA-PLUS group has the highest mean reading scores in all three groups, while DRTA group has the second highest with the Control group being the lowest. However, DRTA-PLUS group also has the most spread out reading score distribution, and DRTA group has the second most spread out distribution while Control group is the least spread out. Both DRTA-PLUS and Control groups display a roughly even distribution while the DTRA group displayed an approximately normal distribution centered around x = 6 that has a few extreme outliers on both ends.

# Question 3

Perform a frequentist hypothesis test to determine whether the mean reading scores differ between the three groups (“main effect”). Simply report the F-test, along with a p-value of this main effect. Then test all possible pairwise mean differences, and report them along with a 95% confidence interval, and p-values for all comparisons in a single table. For this set of hypothesis tests, assume that the tester is comfortable with using a Type I error rate of 5% for all significance tests. In other words, do not adjust any p-values for multiple testing. Summarize your results. Expected length is 1-3 sentences.

```{r}
lm <- lm(posttest ~ group, data = df)

joint_tests(lm) |>
  select(F.ratio, p.value) |>
  kable(caption = "Frequentist Analysis Results", digits = 6)

summary(emmeans(lm, "group", contr = "pairwise", adjust="tukey"), 
        infer = TRUE)$contrasts |>
  select(contrast, estimate, lower.CL, upper.CL, p.value) |>
  rename(lower.CI = lower.CL, upper.CI = upper.CL) |>
  kable(caption = "Frequentist Analysis Results", digits = 4)
```

The Frequentist analysis resulted in an F ratio of 8.407 and p-value of 0.00058 for the main effect; this means that difference in mean reading scores between three groups is statistically significant. For the pairwise mean differences analysis, the differences in mean reading scores between Control and DRTA-PLUS as well as between DRTA and DRTA-PLUS yielded a significant result as the p-values are 0.0006 and 0.0113, respectively. Their 95% confidence intervals also match up with the significant results since the CI's do not include 0. The difference in mean reading scores between Control and DRTA was not statistically significant, and the 95% confidence also match up with this conclusion since the CI includes 0. Overall, the analysis means that we have convincing evidence suggesting the Control and DRTA-PLUS pair as well as DRTA and DRTA-PLUS pair yield statistically different reading scores within each pair.

# Question 4

Redo the previous analysis using Bayesian statistics. Report a Bayes Factor (using default priors in the BayesFactor package) to answer the question whether there is a “main effect”. Then report point (Bayesian) estimates and 95% credible intervals, for each pairwise mean differences between groups and display them in a single table. For the estimation of the Bayesian mean differences use rstanarm or brms with the following priors. Prior on the intercept that is normally distributed, centered on 0, with a standard deviation of 3, and autoscale=TRUE. For other coeﬀicients (here the group mean differences) use a prior centered around 0 (indicating that there is no prior information whether the treatment is positive or negative), with a standard deviation of 3, again with autoscale=TRUE. Summarize your results. Expected length is 1-3 sentences.

```{r message=FALSE, warning=FALSE}
set.seed(5750)
anovaBF(posttest ~ group, data = df) |>
  extractBF(onlybf = TRUE) |>
  kable(digits = 2, col.names = "BF")
```

```{r cache=TRUE, results="hide", message=FALSE, warning=FALSE}
blm <- stan_glm(posttest ~ group, data = df, family = gaussian(),
                prior_intercept = normal(0, 3, autoscale = TRUE),
                prior = normal(0, 3, autoscale = TRUE))
```

```{r}
summary(emmeans(blm, specs = "group", contr = "pairwise"))$contrasts |>
  tibble() |>
  kable(caption = "Bayesian Analysis Results", digits = 4)
```

The Bayesian analysis resulted in a BF of 54.08 for the main effect; this means we have very strong evidence for the alternative hypothesis suggesting the mean reading scores between three groups are different. For pairwise analysis, the 95% credible intervals for the Control and DRTA-PLUS pair as well as DRTA and DRTA-PLUS pair did not include 0, which means we have convincing evidence suggesting the difference in reading scores are different within each pair. For the Control and DRTA pair, since the 95% credible interval includes 0, we have inconclusive results for the difference in mean reading scores between the two groups.

# Question 5

Using both Frequentist and Bayesian methods, code the following contrast, and report p-values, Bayes Factor, confidence intervals, and credible intervals. A difference between the control group and an unweighted average of the two treatment groups. For the Bayes Factor, use the describe_posterior function on an emmeans object, and use a point-null prior (default) and the prior from your Bayesian model from question 4 as the alternative. Summarize your results. Expected length is 1-3 sentences.

```{r}
summary(emmeans(lm, specs = "group", 
                contr = list(control_vs_avg = c(1, -0.5, -0.5)), 
                adjust = "none", infer = TRUE))$contrasts |>
  select(contrast, lower.CL, upper.CL, p.value) |>
  rename(lower.CI = lower.CL, upper.CI = upper.CL) |>  
  kable(caption = "Frequentist Analysis Results", digits = 4)
```

```{r message=FALSE, warning=FALSE}
set.seed(5750)
describe_posterior(emmeans(blm, specs = "group", 
             contr = list(control_vs_avg = c(1, -0.5, -0.5)))$contrasts, 
             test="bayesfactor", bf_prior = blm) |>
  mutate(BF = exp(log_BF)) |>
  select(contrast, CI_low, CI_high, BF) |>
  kable(caption = "Bayesian Analysis Results", digits = 2)
```

The Frequentist analysis resulted in a p-value of 0.0065, which means we have convincing evidence suggesting that the difference between the control and an unweighted average of two treatment groups is statistically significant. The 95% confidence interval of (-2.9911, -0.5089) also matches up to suggest the difference is statistically significant since it does not include 0. The Bayesian analysis resulted in a BF of 2.42, which means we have anecdotal evidence suggesting that that the difference between the control and an unweighted average of two treatment groups is different. The 95% credible interval of (-2.93, -0.52) also suggests that there is difference in mean reading scores since it does not include 0.

# Question 6

Conduct an equivalence test to answer the following question. Can the null-hypothesis of non-equivalence with the following criteria be rejected? Is the difference between the mean of Group 1 (control), and the unweighted average of Group 2 and Group 3 within a region of equivalence that is centered around 0 and stretches 2.5 (raw) units in both directions. Perform this analysis using both Frequentist and Bayesian statistics. For the Frequentist test, simply report the p-value and provide a one sentence explanation. For the Bayesian analysis, it is very complex to use bridgesampling and brms, because the effect of interest (here an unweighted complex contrast) cannot be easily mapped onto coeﬀicients in the models which are the target of the priors. Instead use the Bayesian ROPE (region of practical equivalence) approach suggested by Kruschke. It is very simple, and implemented in the describe_posterior function. It simply asks the question whether a 95% Bayesian credible interval is or is not fully enclosed in a pre-specified region. If the credible interval is fully enclosed in the ROPE, the hypothesis of equivalence is accepted. If the credible interval is completely outside the ROPE, then equivalence is rejected. Any partial overlap yields an inconclusive result. Use describe_posterior to conduct the Bayesian equivalence test and check whether the 95% credible interval of the contrast is contained in a ROPE that is centered on 0 and stretches 2.5 units in both directions. Report the output of the Bayesian analysis.

```{r}
summary(emmeans(lm, specs = "group", 
                contr = list(control_vs_avg = c(1, -0.5, -0.5)), 
                adjust = "none", infer = TRUE), 
        delta = 2.5, side = "equivalence")$contrasts |>
  select(contrast, p.value) |>
  kable(caption = "Frequentist Analysis Results", digits = 2)
```

```{r warning=FALSE}
describe_posterior(emmeans(blm, specs = "group", 
                           contr = list(control_vs_avg = 
                                          c(1, -0.5, -0.5)))$contrasts, 
                   rope_range = c(-2.5, 2.5)) |>
  select(contrast, CI_low, CI_high) |>
  kable(caption = "Bayesian Analysis Results", digits = 2)
```

The Frequentist analysis resulted in a p-value of 0.12, which means we fail to reject the null hypothesis of non-equivalence between the Control and the unweighted average of two treatment groups within a region of equivalence that is centered around 0 and stretches 2.5 (raw) units in both directions. The Bayesian analysis resulted in a 95% credible interval of (-2.93, -0.52) contained in a ROPE that is centered on 0 and stretches 2.5 units in both directions. Since the credible interval has a partial overlap with the ROPE but also spills over, we have inconclusive results for the test of rejecting equivalence.

# Question 7

Conduct a frequentist power analysis in which you desire to compute the required sample size a-priori on the following design. A simple two-group study in which participants are randomly assigned to either treatment A, or treatment B. The effect of interest for which you wish to conduct a power analysis is the group mean difference between treatment A and treatment B. In particular, you are interested in a frequentist hypothesis test to test whether treatment A is significantly larger than treatment B. The desired Type I error rate is 5%, and the desired Type II error rate is 10%. The smallest effect size of interest that you do not want to miss is .2 on a standardized metric. Report the required sample size.

```{r}
pwr.t.test(d = 0.2, sig.level = 0.05, power = 0.90, 
                             type = "two.sample", alternative = "greater")
```

The Frequentist power analysis resulted in a required sample size of 429 for each group, which means we need at least a total of 858 participants across the two groups.
